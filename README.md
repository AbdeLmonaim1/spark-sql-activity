# ğŸš´â€â™‚ï¸ Bike Sharing Analysis - Apache Spark SQL Activity

<div align="center">

![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5.1-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Java](https://img.shields.io/badge/Java-21-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)
![Maven](https://img.shields.io/badge/Maven-3.9+-C71A36?style=for-the-badge&logo=apache-maven&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

**A comprehensive hands-on project demonstrating Apache Spark SQL capabilities through bike rental data analysis**

[Features](#-features) â€¢ [Technologies](#-technologies-used) â€¢ [Getting Started](#-getting-started) â€¢ [Usage](#-usage) â€¢ [Exercises](#-exercises-covered) â€¢ [Troubleshooting](#-troubleshooting)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Technologies Used](#-technologies-used)
- [Project Structure](#-project-structure)
- [Prerequisites](#-prerequisites)
- [Getting Started](#-getting-started)
- [Usage](#-usage)
- [Exercises Covered](#-exercises-covered)
- [Sample Output](#-sample-output)
- [Troubleshooting](#-troubleshooting)
- [Learning Outcomes](#-learning-outcomes)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

This project is a **practical Big Data analytics activity** that demonstrates the power of **Apache Spark SQL** for analyzing bike-sharing rental data. It covers essential Spark SQL operations including data loading, temporary views, SQL queries, aggregations, time-based analysis, and user behavior insights.

The project simulates a real-world scenario where a bike-sharing company wants to analyze rental patterns, user demographics, peak hours, popular routes, and revenue metrics to make data-driven business decisions.

---

## âœ¨ Features

- ğŸ”„ **Automated Data Generation** - Generate realistic bike rental datasets with customizable size
- ğŸ“Š **Comprehensive SQL Analysis** - 6 major exercise categories covering different aspects of data analysis
- â° **Time-Based Insights** - Peak hour analysis and temporal pattern detection
- ğŸ‘¥ **User Behavior Analytics** - Demographic analysis by age groups and gender
- ğŸ’° **Revenue Analysis** - Profitability metrics and pricing patterns
- ğŸ—ºï¸ **Route Analysis** - Popular stations and profitable routes identification
- ğŸ¨ **Clean Console Output** - Well-formatted results with clear section headers

---

## ğŸ› ï¸ Technologies Used

| Technology | Version | Purpose |
|------------|---------|---------|
| **Apache Spark** | `3.5.1` | Distributed data processing engine |
| **Spark SQL** | `3.5.1` | SQL query engine for structured data |
| **Java** | `21` | Primary programming language |
| **Maven** | `3.9+` | Dependency management and build tool |
| **SLF4J** | `2.0.9` | Logging framework |
| **Scala** | `2.13` | Spark's underlying language (runtime) |

### Key Spark Components

- **SparkSession** - Entry point for Spark SQL functionality
- **Dataset<Row>** - Distributed collection of data organized into named columns
- **Temporary Views** - In-memory SQL tables for query execution
- **DataFrame API** - High-level API for structured data manipulation

---

## ğŸ“ Project Structure

```
spark-sql-activity/
â”‚
â”œâ”€â”€ .mvn/
â”‚   â””â”€â”€ jvm.config                    # JVM arguments for Java 21 compatibility
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ java/
â”‚           â””â”€â”€ ma/
â”‚               â””â”€â”€ enset/
â”‚                   â”œâ”€â”€ BikeRentalAnalysis.java    # Main analysis application
â”‚                   â””â”€â”€ data/
â”‚                       â””â”€â”€ DataGenerator.java     # CSV data generator
â”‚
â”œâ”€â”€ bike_sharing.csv                  # Generated sample data (1000 records)
â”œâ”€â”€ pom.xml                           # Maven configuration
â””â”€â”€ README.md                         # This file
```

---

## ğŸ“¦ Prerequisites

Before running this project, ensure you have:

- âœ… **Java Development Kit (JDK) 21** or **JDK 17** installed
- âœ… **Apache Maven 3.9+** installed
- âœ… **Minimum 4GB RAM** (recommended for Spark)
- âœ… **Windows 10/11**, **Linux**, or **macOS**

### Verify Installation

```bash
# Check Java version
java -version

# Check Maven version
mvn -version
```

---

## ğŸš€ Getting Started

### Step 1: Clone or Download the Project

```bash
cd e:\D\Master_SDIA\S3\Big_Data\spark-sql-activity
```

### Step 2: Generate Sample Data

First, generate the bike rental dataset:

```bash
mvn clean compile exec:java -Dexec.mainClass="ma.enset.data.DataGenerator"
```

This creates `bike_sharing.csv` with **1000 sample records** containing:
- Rental ID, User ID, Age, Gender
- Start/End timestamps
- Start/End stations
- Duration and Price

### Step 3: Run the Analysis

Execute the main analysis application:

```bash
mvn clean compile exec:java -Dexec.mainClass="ma.enset.BikeRentalAnalysis" -Dexec.cleanupDaemonThreads=false
```

---

## ğŸ’» Usage

### Running from IDE (IntelliJ IDEA / Eclipse)

If you're using an IDE, you need to add **JVM arguments** for Java 21 compatibility:

#### IntelliJ IDEA
1. Right-click on `BikeRentalAnalysis.java` â†’ **Modify Run Configuration**
2. Add to **VM options**:
```
--add-opens=java.base/java.lang=ALL-UNNAMED
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED
--add-opens=java.base/java.lang.reflect=ALL-UNNAMED
--add-opens=java.base/java.io=ALL-UNNAMED
--add-opens=java.base/java.net=ALL-UNNAMED
--add-opens=java.base/java.nio=ALL-UNNAMED
--add-opens=java.base/java.util=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED
--add-opens=java.base/sun.nio.cs=ALL-UNNAMED
--add-opens=java.base/sun.security.action=ALL-UNNAMED
--add-opens=java.base/sun.util.calendar=ALL-UNNAMED
```

### Alternative: Use Java 17

To avoid JVM arguments, downgrade to Java 17:

1. Update `pom.xml` lines 12-13 and 45-46:
```xml
<maven.compiler.source>17</maven.compiler.source>
<maven.compiler.target>17</maven.compiler.target>
```

2. Configure your IDE to use JDK 17
3. Run normally without special arguments

---

## ğŸ“š Exercises Covered

### ğŸ”¹ Exercise 1: Data Loading & Exploration
- Load CSV file with schema inference
- Display DataFrame schema
- Show sample records
- Count total rentals

### ğŸ”¹ Exercise 2: Create Temporary View
- Register DataFrame as SQL temporary view
- Verify view accessibility

### ğŸ”¹ Exercise 3: Basic SQL Queries
- Filter rentals by duration (`> 30 minutes`)
- Filter by specific station (`Station A`)
- Calculate total revenue using `SUM()` aggregation

### ğŸ”¹ Exercise 4: Aggregation Queries
- Count rentals per station with `GROUP BY`
- Calculate average duration per station
- Find station with highest rental count using `ORDER BY` and `LIMIT`

### ğŸ”¹ Exercise 5: Time-Based Analysis
- Extract hour from timestamp using `HOUR()` function
- Identify peak rental hours
- Find most popular morning station (7 AM - 12 PM)

### ğŸ”¹ Exercise 6: User Behavior Analysis
- Calculate average user age
- Analyze rentals by gender distribution
- Segment users into age groups using `CASE WHEN`

### ğŸ Bonus: Additional Insights
- Most profitable routes (station pairs)
- Average price by duration categories
- Revenue optimization opportunities

---

## ğŸ“Š Sample Output

When you run the analysis, you'll see structured output like this:

```
========================================
BIKE SHARING ANALYSIS - SPARK SQL
========================================

--- EXERCISE 1: Data Loading & Exploration ---

1. Loading data from bike_sharing.csv...
Chemin du fichier: E:\D\Master_SDIA\S3\Big_Data\spark-sql-activity\bike_sharing.csv
âœ“ Data loaded successfully

2. Schema:
root
 |-- rental_id: integer (nullable = true)
 |-- user_id: integer (nullable = true)
 |-- age: integer (nullable = true)
 |-- gender: string (nullable = true)
 |-- start_time: timestamp (nullable = true)
 |-- end_time: timestamp (nullable = true)
 |-- start_station: string (nullable = true)
 |-- end_station: string (nullable = true)
 |-- duration_minutes: integer (nullable = true)
 |-- price: double (nullable = true)

4. Total number of rentals: 1000

--- EXERCISE 5: Time-Based Analysis ---

Top 3 Peak Hours:
+----+------------+
|hour|rental_count|
+----+------------+
|14  |55          |
|8   |52          |
|17  |49          |
+----+------------+
```

---

## ğŸ”§ Troubleshooting

### âŒ Error: `IllegalAccessError: sun.nio.ch.DirectBuffer`

**Cause:** Java 21 module access restrictions

**Solution:** Use the Maven command with proper configuration (already set up in `.mvn/jvm.config`):
```bash
mvn clean compile exec:java -Dexec.mainClass="ma.enset.BikeRentalAnalysis" -Dexec.cleanupDaemonThreads=false
```

### âŒ Error: `Unable to resolve table 'bike_rentals_view'`

**Cause:** CSV file not found or empty

**Solution:** 
1. Run `DataGenerator` first to create the CSV
2. Verify `bike_sharing.csv` exists in the project root
3. Check file is not empty (should be ~80KB for 1000 records)

### âŒ Error: `HADOOP_HOME is unset`

**Cause:** Windows-specific Hadoop warning (harmless)

**Solution:** This is just a warning and doesn't affect functionality. You can safely ignore it.

### âŒ Maven Build Fails

**Solution:**
```bash
# Clean and rebuild
mvn clean install -U

# If still failing, check Maven settings
mvn -version
```

---

## ğŸ“ Learning Outcomes

By completing this activity, you will learn:

- âœ… How to initialize and configure a **SparkSession**
- âœ… Loading and exploring data with **Spark DataFrames**
- âœ… Creating and using **Temporary SQL Views**
- âœ… Writing **SQL queries** in Spark (SELECT, WHERE, GROUP BY, ORDER BY)
- âœ… Using **aggregate functions** (COUNT, SUM, AVG, ROUND)
- âœ… Working with **timestamp functions** (HOUR, BETWEEN)
- âœ… Implementing **conditional logic** with CASE WHEN
- âœ… Performing **multi-level aggregations** and **window operations**
- âœ… Analyzing **real-world business metrics** with Big Data tools
- âœ… Understanding **Spark SQL optimization** and best practices

---

## ğŸ¤ Contributing

Contributions are welcome! Here are some ideas for enhancements:

- ğŸ“ˆ Add data visualization with Apache Zeppelin or Jupyter
- ğŸŒ Implement geospatial analysis for station locations
- ğŸ¤– Add machine learning models for demand prediction
- ğŸ“Š Create interactive dashboards with Spark + Tableau
- ğŸ”„ Implement streaming analysis with Spark Structured Streaming

---

## ğŸ“„ License

This project is licensed under the **MIT License** - feel free to use it for educational purposes.

---

## ğŸ‘¨â€ğŸ’» Author

**Master SDIA - Big Data Course**  
*Semester 3 - Spark SQL Activity*

---

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the [Troubleshooting](#-troubleshooting) section
2. Review [Apache Spark Documentation](https://spark.apache.org/docs/3.5.1/)
3. Consult [Spark SQL Guide](https://spark.apache.org/docs/3.5.1/sql-programming-guide.html)

---

<div align="center">

### â­ If you found this project helpful, please give it a star!

**Made with â¤ï¸ using Apache Spark**

</div>
